"""
üß† MODU≈Å ROZUMOWANIA ABSTRAKCYJNEGO - ADVANCED REASONING ENGINE
==============================================================

Centralny system logicznego wnioskowania, rozumowania przyczynowo-skutkowego 
i abstrakcyjnego my≈õlenia symbolicznego dla AGI-Enhanced MGA System.

Implementuje:
- Dedukcjƒô, Indukcjƒô, Abdukcjƒô
- Rozumowanie przyczynowo-skutkowe  
- My≈õlenie symboliczne i reprezentacje abstrakcyjne
- Planowanie wieloetapowe i hierarchiczne
- Rozumowanie w niepewno≈õci (probabilistic reasoning)

Cel: +16 punkt√≥w AGI (4 pkt ‚Üí 20 pkt jako≈õci rozumowania)
"""

import logging
from typing import Dict, List, Optional, Any, Tuple, Union, Set
from dataclasses import dataclass, field
from enum import Enum
from datetime import datetime
import uuid
import numpy as np
import json
from collections import defaultdict, deque
import random
import math
import networkx as nx
from itertools import combinations, permutations

# Konfiguracja loggingu
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger('AbstractReasoning')

class ReasoningType(Enum):
    """Typy rozumowania logicznego"""
    DEDUCTION = "deduction"          # Z og√≥lnego do szczeg√≥≈Çowego
    INDUCTION = "induction"          # Z przyk≈Çad√≥w do regu≈Ç
    ABDUCTION = "abduction"          # Najlepsze wyja≈õnienie
    CAUSAL = "causal"               # Przyczynowo-skutkowe
    ANALOGICAL = "analogical"       # Przez analogiƒô
    PROBABILISTIC = "probabilistic" # W niepewno≈õci

class LogicalOperator(Enum):
    """Operatory logiczne"""
    AND = "and"
    OR = "or"
    NOT = "not"
    IMPLIES = "implies"
    IFF = "if_and_only_if"
    FORALL = "for_all"
    EXISTS = "exists"

@dataclass
class LogicalStatement:
    """Pojedyncze stwierdzenie logiczne"""
    id: str
    content: str
    variables: List[str] = field(default_factory=list)
    predicates: List[str] = field(default_factory=list)
    truth_value: Optional[bool] = None
    confidence: float = 0.5
    source: str = "unknown"
    timestamp: datetime = field(default_factory=datetime.now)

@dataclass
class ReasoningRule:
    """Regu≈Ça rozumowania"""
    rule_id: str
    rule_type: ReasoningType
    premises: List[LogicalStatement]
    conclusion: LogicalStatement
    confidence: float = 0.8
    usage_count: int = 0
    success_rate: float = 0.0
    created_at: datetime = field(default_factory=datetime.now)

@dataclass
class CausalRelation:
    """Relacja przyczynowo-skutkowa"""
    cause: str
    effect: str
    strength: float  # 0.0 - 1.0
    delay: float = 0.0  # Op√≥≈∫nienie w jednostkach czasu
    confidence: float = 0.5
    evidence_count: int = 1
    context: Dict[str, Any] = field(default_factory=dict)

@dataclass
class ReasoningTrace:
    """≈ölad procesu rozumowania"""
    trace_id: str
    reasoning_type: ReasoningType
    input_premises: List[LogicalStatement]
    reasoning_steps: List[str]
    final_conclusion: Optional[LogicalStatement]
    confidence: float
    execution_time: float
    success: bool
    timestamp: datetime = field(default_factory=datetime.now)

class SymbolicKnowledgeBase:
    """Baza wiedzy symbolicznej"""
    
    def __init__(self):
        self.statements: Dict[str, LogicalStatement] = {}
        self.rules: Dict[str, ReasoningRule] = {}
        self.concepts: Dict[str, Dict[str, Any]] = {}
        self.hierarchies: Dict[str, Set[str]] = defaultdict(set)  # parent -> children
        self.causal_graph = nx.DiGraph()
        logger.info("Zainicjalizowano bazƒô wiedzy symbolicznej")
    
    def add_statement(self, statement: LogicalStatement) -> str:
        """Dodaje stwierdzenie do bazy wiedzy"""
        self.statements[statement.id] = statement
        
        # Automatyczne wykrywanie koncept√≥w
        for predicate in statement.predicates:
            if predicate not in self.concepts:
                self.concepts[predicate] = {
                    "instances": set(),
                    "properties": set(),
                    "relations": set()
                }
        
        return statement.id
    
    def add_rule(self, rule: ReasoningRule) -> str:
        """Dodaje regu≈Çƒô rozumowania"""
        self.rules[rule.rule_id] = rule
        return rule.rule_id
    
    def add_causal_relation(self, relation: CausalRelation):
        """Dodaje relacjƒô przyczynowo-skutkowƒÖ"""
        self.causal_graph.add_edge(
            relation.cause, 
            relation.effect,
            weight=relation.strength,
            delay=relation.delay,
            confidence=relation.confidence,
            evidence=relation.evidence_count
        )
    
    def create_concept_hierarchy(self, parent: str, children: List[str]):
        """Tworzy hierarchiƒô koncept√≥w (is-a relationships)"""
        self.hierarchies[parent].update(children)
        for child in children:
            if child not in self.concepts:
                self.concepts[child] = {"parent": parent, "properties": set(), "instances": set()}
    
    def get_ancestors(self, concept: str) -> Set[str]:
        """Zwraca wszystkich przodk√≥w konceptu"""
        ancestors = set()
        for parent, children in self.hierarchies.items():
            if concept in children:
                ancestors.add(parent)
                ancestors.update(self.get_ancestors(parent))
        return ancestors
    
    def get_descendants(self, concept: str) -> Set[str]:
        """Zwraca wszystkich potomk√≥w konceptu"""
        return self.hierarchies.get(concept, set())

class DeductiveReasoning:
    """Silnik rozumowania dedukcyjnego"""
    
    def __init__(self, knowledge_base: SymbolicKnowledgeBase):
        self.kb = knowledge_base
        self.modus_ponens_count = 0
        self.modus_tollens_count = 0
    
    def modus_ponens(self, major_premise: LogicalStatement, 
                    minor_premise: LogicalStatement) -> Optional[LogicalStatement]:
        """
        Modus Ponens: Je≈õli A ‚Üí B i A, to B
        """
        try:
            # Sprawd≈∫ czy major_premise ma formƒô implikacji
            if "‚Üí" in major_premise.content or "implies" in major_premise.content:
                # Parsuj implikacjƒô (uproszczone)
                parts = major_premise.content.replace("‚Üí", "implies").split("implies")
                if len(parts) == 2:
                    antecedent = parts[0].strip()
                    consequent = parts[1].strip()
                    
                    # Sprawd≈∫ czy minor_premise potwierdza antecedent
                    if antecedent.lower() in minor_premise.content.lower():
                        conclusion = LogicalStatement(
                            id=str(uuid.uuid4()),
                            content=consequent,
                            confidence=min(major_premise.confidence, minor_premise.confidence) * 0.9,
                            source="modus_ponens",
                            predicates=[consequent]
                        )
                        
                        self.modus_ponens_count += 1
                        logger.info(f"Modus Ponens: {antecedent} + {minor_premise.content} ‚Üí {consequent}")
                        return conclusion
            
            return None
            
        except Exception as e:
            logger.error(f"B≈ÇƒÖd w Modus Ponens: {e}")
            return None
    
    def modus_tollens(self, major_premise: LogicalStatement,
                     minor_premise: LogicalStatement) -> Optional[LogicalStatement]:
        """
        Modus Tollens: Je≈õli A ‚Üí B i ¬¨B, to ¬¨A
        """
        try:
            if "‚Üí" in major_premise.content or "implies" in major_premise.content:
                parts = major_premise.content.replace("‚Üí", "implies").split("implies")
                if len(parts) == 2:
                    antecedent = parts[0].strip()
                    consequent = parts[1].strip()
                    
                    # Sprawd≈∫ czy minor_premise neguje consequent
                    if ("not" in minor_premise.content.lower() and 
                        consequent.lower() in minor_premise.content.lower()):
                        
                        conclusion = LogicalStatement(
                            id=str(uuid.uuid4()),
                            content=f"not {antecedent}",
                            confidence=min(major_premise.confidence, minor_premise.confidence) * 0.85,
                            source="modus_tollens",
                            predicates=[f"¬¨{antecedent}"]
                        )
                        
                        self.modus_tollens_count += 1
                        logger.info(f"Modus Tollens: ¬¨{consequent} ‚Üí ¬¨{antecedent}")
                        return conclusion
            
            return None
            
        except Exception as e:
            logger.error(f"B≈ÇƒÖd w Modus Tollens: {e}")
            return None
    
    def syllogism(self, major: LogicalStatement, minor: LogicalStatement) -> Optional[LogicalStatement]:
        """
        Sylogizm kategoryczny: Wszyscy A sƒÖ B, C jest A, wiƒôc C jest B
        """
        try:
            # Uproszczona implementacja sylogizmu
            if ("all" in major.content.lower() or "every" in major.content.lower()):
                # Parse: "All X are Y"
                major_parts = major.content.lower().replace("all ", "").replace("every ", "").split(" are ")
                if len(major_parts) == 2:
                    category_A = major_parts[0].strip()
                    category_B = major_parts[1].strip()
                    
                    # Parse: "C is A"
                    if "is" in minor.content.lower():
                        minor_parts = minor.content.lower().split(" is ")
                        if len(minor_parts) == 2:
                            individual_C = minor_parts[0].strip()
                            category_check = minor_parts[1].strip()
                            
                            if category_A == category_check:
                                conclusion = LogicalStatement(
                                    id=str(uuid.uuid4()),
                                    content=f"{individual_C} is {category_B}",
                                    confidence=min(major.confidence, minor.confidence) * 0.9,
                                    source="syllogism",
                                    predicates=[category_B, individual_C]
                                )
                                
                                logger.info(f"Sylogizm: {individual_C} ‚àà {category_A} ‚àß {category_A} ‚äÜ {category_B} ‚Üí {individual_C} ‚àà {category_B}")
                                return conclusion
            
            return None
            
        except Exception as e:
            logger.error(f"B≈ÇƒÖd w sylogizmie: {e}")
            return None

class InductiveReasoning:
    """Silnik rozumowania indukcyjnego"""
    
    def __init__(self, knowledge_base: SymbolicKnowledgeBase):
        self.kb = knowledge_base
        self.patterns_discovered = 0
        self.generalizations_made = 0
    
    def generalize_from_examples(self, examples: List[LogicalStatement],
                                min_confidence: float = 0.6) -> Optional[LogicalStatement]:
        """
        Generalizacja z przyk≈Çad√≥w - wykrywa wsp√≥lne wzorce
        """
        if len(examples) < 2:
            return None
        
        # Znajd≈∫ wsp√≥lne predykaty
        common_predicates = set(examples[0].predicates)
        for example in examples[1:]:
            common_predicates &= set(example.predicates)
        
        if not common_predicates:
            return None
        
        # Znajd≈∫ wsp√≥lne s≈Çowa w tre≈õci
        common_words = set(examples[0].content.lower().split())
        for example in examples[1:]:
            common_words &= set(example.content.lower().split())
        
        # Usu≈Ñ stop words
        stop_words = {"is", "are", "the", "a", "an", "and", "or", "but", "in", "on", "at", "to", "for"}
        common_words -= stop_words
        
        if common_words:
            # Tw√≥rz generalizacjƒô
            pattern = " ".join(sorted(common_words))
            generalization = LogicalStatement(
                id=str(uuid.uuid4()),
                content=f"Generally: {pattern}",
                confidence=min(len(examples) / 10.0, 1.0) * min_confidence,
                source="inductive_generalization",
                predicates=list(common_predicates)
            )
            
            self.generalizations_made += 1
            logger.info(f"Indukcja: Generalizacja z {len(examples)} przyk≈Çad√≥w ‚Üí {pattern}")
            return generalization
        
        return None
    
    def discover_statistical_pattern(self, data_points: List[Dict[str, Any]],
                                   threshold: float = 0.7) -> List[ReasoningRule]:
        """
        Odkrywa wzorce statystyczne w danych
        """
        patterns = []
        
        if len(data_points) < 3:
            return patterns
        
        # Znajd≈∫ korelacje miƒôdzy w≈Ça≈õciwo≈õciami
        properties = set()
        for point in data_points:
            properties.update(point.keys())
        
        properties = list(properties)
        
        # Sprawd≈∫ korelacje parami
        for prop1, prop2 in combinations(properties, 2):
            correlations = []
            for point in data_points:
                if prop1 in point and prop2 in point:
                    # Uproszczona korelacja (binary)
                    val1 = 1 if point[prop1] else 0
                    val2 = 1 if point[prop2] else 0
                    correlations.append((val1, val2))
            
            if len(correlations) >= 3:
                # Oblicz wsp√≥≈Çczynnik korelacji (uproszczony)
                positive_correlations = sum(1 for v1, v2 in correlations if v1 == v2)
                correlation_strength = positive_correlations / len(correlations)
                
                if correlation_strength >= threshold:
                    rule = ReasoningRule(
                        rule_id=str(uuid.uuid4()),
                        rule_type=ReasoningType.INDUCTION,
                        premises=[LogicalStatement(
                            id=str(uuid.uuid4()),
                            content=f"{prop1} is true",
                            predicates=[prop1]
                        )],
                        conclusion=LogicalStatement(
                            id=str(uuid.uuid4()),
                            content=f"{prop2} is likely true",
                            predicates=[prop2],
                            confidence=correlation_strength
                        ),
                        confidence=correlation_strength
                    )
                    patterns.append(rule)
                    
                    self.patterns_discovered += 1
                    logger.info(f"Odkryto wzorzec: {prop1} ‚Üí {prop2} (si≈Ça: {correlation_strength:.2f})")
        
        return patterns

class AbductiveReasoning:
    """Silnik rozumowania abdukcyjnego (inference to the best explanation)"""
    
    def __init__(self, knowledge_base: SymbolicKnowledgeBase):
        self.kb = knowledge_base
        self.hypotheses_generated = 0
        self.explanations_ranked = 0
    
    def generate_hypotheses(self, observation: LogicalStatement,
                          max_hypotheses: int = 5) -> List[LogicalStatement]:
        """
        Generuje hipotezy wyja≈õniajƒÖce obserwacjƒô
        """
        hypotheses = []
        
        # Szukaj regu≈Ç, kt√≥re mogƒÖ wyja≈õniƒá obserwacjƒô
        for rule in self.kb.rules.values():
            if rule.rule_type in [ReasoningType.DEDUCTION, ReasoningType.CAUSAL]:
                # Sprawd≈∫ czy wniosek regu≈Çy pasuje do obserwacji
                conclusion_words = set(rule.conclusion.content.lower().split())
                observation_words = set(observation.content.lower().split())
                
                overlap = len(conclusion_words & observation_words)
                if overlap > 0:
                    # Utw√≥rz hipotezƒô na podstawie przes≈Çanek regu≈Çy
                    for premise in rule.premises:
                        hypothesis = LogicalStatement(
                            id=str(uuid.uuid4()),
                            content=f"Hypothetically: {premise.content}",
                            confidence=rule.confidence * 0.7,  # Obni≈º pewno≈õƒá dla hipotezy
                            source="abductive_hypothesis",
                            predicates=premise.predicates.copy()
                        )
                        hypotheses.append(hypothesis)
        
        # Generuj te≈º hipotezy na podstawie hierarchii koncept√≥w
        for predicate in observation.predicates:
            ancestors = self.kb.get_ancestors(predicate)
            for ancestor in ancestors:
                hypothesis = LogicalStatement(
                    id=str(uuid.uuid4()),
                    content=f"Possibly due to {ancestor} property",
                    confidence=0.6,
                    source="hierarchical_hypothesis",
                    predicates=[ancestor]
                )
                hypotheses.append(hypothesis)
        
        # Sortuj wed≈Çug pewno≈õci i zwr√≥ƒá najlepsze
        hypotheses.sort(key=lambda h: h.confidence, reverse=True)
        self.hypotheses_generated += len(hypotheses[:max_hypotheses])
        
        logger.info(f"Abdukcja: Wygenerowano {len(hypotheses[:max_hypotheses])} hipotez dla: {observation.content}")
        return hypotheses[:max_hypotheses]
    
    def rank_explanations(self, hypotheses: List[LogicalStatement],
                         criteria: Dict[str, float] = None) -> List[Tuple[LogicalStatement, float]]:
        """
        Rankinguje hipotezy wed≈Çug kryteri√≥w jako≈õci wyja≈õnienia
        """
        if criteria is None:
            criteria = {
                "simplicity": 0.3,    # Prostsze wyja≈õnienia sƒÖ lepsze
                "prior_probability": 0.3,  # Bardziej prawdopodobne hipotezy
                "explanatory_power": 0.4   # Si≈Ça wyja≈õniajƒÖca
            }
        
        ranked_hypotheses = []
        
        for hypothesis in hypotheses:
            # Oblicz prostotƒô (mniej s≈Ç√≥w = prostsze)
            simplicity_score = 1.0 / (len(hypothesis.content.split()) + 1)
            
            # Prawdopodobie≈Ñstwo a priori (na podstawie confidence)
            prior_prob_score = hypothesis.confidence
            
            # Si≈Ça wyja≈õniajƒÖca (na podstawie liczby predykat√≥w)
            explanatory_power = min(1.0, len(hypothesis.predicates) / 3.0)
            
            # Ko≈Ñcowy wynik
            total_score = (
                criteria["simplicity"] * simplicity_score +
                criteria["prior_probability"] * prior_prob_score +
                criteria["explanatory_power"] * explanatory_power
            )
            
            ranked_hypotheses.append((hypothesis, total_score))
        
        # Sortuj wed≈Çug wyniku
        ranked_hypotheses.sort(key=lambda x: x[1], reverse=True)
        
        self.explanations_ranked += 1
        logger.info(f"Ranking: Oceniono {len(hypotheses)} hipotez")
        
        return ranked_hypotheses

class CausalReasoning:
    """Silnik rozumowania przyczynowo-skutkowego"""
    
    def __init__(self, knowledge_base: SymbolicKnowledgeBase):
        self.kb = knowledge_base
        self.causal_inferences = 0
        self.interventions_simulated = 0
    
    def infer_causal_chain(self, cause: str, max_depth: int = 5) -> List[List[str]]:
        """
        Znajduje ≈Ça≈Ñcuchy przyczynowe od danej przyczyny
        """
        chains = []
        
        def find_chains_recursive(current_node: str, current_chain: List[str], depth: int):
            if depth >= max_depth:
                return
            
            # Znajd≈∫ bezpo≈õrednie skutki
            if current_node in self.kb.causal_graph:
                for successor in self.kb.causal_graph.successors(current_node):
                    new_chain = current_chain + [successor]
                    chains.append(new_chain.copy())
                    
                    # Kontynuuj rekursywnie
                    find_chains_recursive(successor, new_chain, depth + 1)
        
        find_chains_recursive(cause, [cause], 0)
        
        self.causal_inferences += len(chains)
        logger.info(f"Znaleziono {len(chains)} ≈Ça≈Ñcuch√≥w przyczynowych od: {cause}")
        
        return chains
    
    def simulate_intervention(self, intervention_node: str, 
                            intervention_value: bool) -> Dict[str, float]:
        """
        Symuluje interwencjƒô (do-operator) i przewiduje skutki
        """
        predicted_effects = {}
        
        # Pearl's do-calculus uproszczony - usu≈Ñ wszystkie krawƒôdzie wchodzƒÖce do wƒôz≈Ça interwencji
        modified_graph = self.kb.causal_graph.copy()
        
        # Usu≈Ñ krawƒôdzie wchodzƒÖce
        incoming_edges = list(modified_graph.in_edges(intervention_node))
        modified_graph.remove_edges_from(incoming_edges)
        
        # Propaguj efekt przez graf
        visited = set()
        queue = [(intervention_node, 1.0 if intervention_value else 0.0)]
        
        while queue:
            current_node, current_strength = queue.pop(0)
            
            if current_node in visited:
                continue
            visited.add(current_node)
            
            # Propaguj do nastƒôpnik√≥w
            for successor in modified_graph.successors(current_node):
                edge_data = modified_graph.get_edge_data(current_node, successor)
                edge_strength = edge_data.get('weight', 0.5)
                
                # Oblicz si≈Çƒô efektu
                effect_strength = current_strength * edge_strength
                predicted_effects[successor] = effect_strength
                
                # Dodaj do kolejki je≈õli efekt jest wystarczajƒÖco silny
                if effect_strength > 0.1:
                    queue.append((successor, effect_strength))
        
        self.interventions_simulated += 1
        logger.info(f"Symulacja interwencji: {intervention_node}={intervention_value} ‚Üí {len(predicted_effects)} efekt√≥w")
        
        return predicted_effects
    
    def find_common_causes(self, effects: List[str]) -> List[str]:
        """
        Znajduje wsp√≥lne przyczyny dla listy skutk√≥w
        """
        if not effects:
            return []
        
        # Znajd≈∫ wszystkich przodk√≥w dla ka≈ºdego skutku
        ancestors_sets = []
        for effect in effects:
            ancestors = set(nx.ancestors(self.kb.causal_graph, effect))
            ancestors_sets.append(ancestors)
        
        # Znajd≈∫ przeciƒôcie - wsp√≥lnych przodk√≥w
        common_ancestors = ancestors_sets[0]
        for ancestors in ancestors_sets[1:]:
            common_ancestors &= ancestors
        
        logger.info(f"Wsp√≥lne przyczyny dla {effects}: {list(common_ancestors)}")
        return list(common_ancestors)

class HierarchicalPlanning:
    """System planowania wieloetapowego i hierarchicznego"""
    
    def __init__(self, knowledge_base: SymbolicKnowledgeBase):
        self.kb = knowledge_base
        self.plans_generated = 0
        self.hierarchical_decompositions = 0
    
    def hierarchical_task_network(self, goal: str, 
                                 available_actions: Dict[str, Dict[str, Any]],
                                 max_depth: int = 5) -> Optional[List[str]]:
        """
        Hierarchiczne planowanie zada≈Ñ (HTN)
        """
        def decompose_task(task: str, depth: int) -> List[str]:
            if depth >= max_depth:
                return [task]
            
            # Sprawd≈∫ czy zadanie mo≈ºna zdekomponowaƒá
            if task in available_actions:
                action_info = available_actions[task]
                subtasks = action_info.get('subtasks', [])
                
                if subtasks:
                    self.hierarchical_decompositions += 1
                    plan = []
                    for subtask in subtasks:
                        plan.extend(decompose_task(subtask, depth + 1))
                    return plan
                else:
                    return [task]  # Zadanie atomowe
            
            return [task]
        
        plan = decompose_task(goal, 0)
        
        if plan:
            self.plans_generated += 1
            logger.info(f"HTN Plan dla '{goal}': {len(plan)} krok√≥w")
        
        return plan if plan else None
    
    def a_star_planning(self, start_state: Dict[str, Any], 
                       goal_state: Dict[str, Any],
                       actions: Dict[str, Dict[str, Any]]) -> Optional[List[str]]:
        """
        Planowanie A* z heurystykƒÖ
        """
        from heapq import heappush, heappop
        
        def state_hash(state):
            return hash(json.dumps(state, sort_keys=True))
        
        def heuristic(state):
            # Prosta heurystyka - liczba r√≥≈ºnic ze stanem docelowym
            differences = 0
            for key, target_value in goal_state.items():
                if state.get(key) != target_value:
                    differences += 1
            return differences
        
        def apply_action(state, action_name, action_def):
            new_state = state.copy()
            effects = action_def.get('effects', {})
            for key, value in effects.items():
                new_state[key] = value
            return new_state
        
        # A* search
        open_set = [(heuristic(start_state), 0, start_state, [])]
        closed_set = set()
        
        while open_set:
            f_cost, g_cost, current_state, path = heappop(open_set)
            
            state_key = state_hash(current_state)
            if state_key in closed_set:
                continue
            
            closed_set.add(state_key)
            
            # Sprawd≈∫ czy osiƒÖgniƒôto cel
            if all(current_state.get(k) == v for k, v in goal_state.items()):
                self.plans_generated += 1
                logger.info(f"A* Plan: {len(path)} krok√≥w od startu do celu")
                return path
            
            # Ekspanduj sƒÖsiad√≥w
            for action_name, action_def in actions.items():
                # Sprawd≈∫ warunki wstƒôpne
                preconditions = action_def.get('preconditions', {})
                if all(current_state.get(k) == v for k, v in preconditions.items()):
                    new_state = apply_action(current_state, action_name, action_def)
                    new_path = path + [action_name]
                    new_g_cost = g_cost + action_def.get('cost', 1)
                    new_f_cost = new_g_cost + heuristic(new_state)
                    
                    heappush(open_set, (new_f_cost, new_g_cost, new_state, new_path))
        
        logger.info("A* Planning: Nie znaleziono planu")
        return None

class ProbabilisticReasoning:
    """Silnik rozumowania probabilistycznego"""
    
    def __init__(self, knowledge_base: SymbolicKnowledgeBase):
        self.kb = knowledge_base
        self.bayesian_inferences = 0
        self.uncertainty_calculations = 0
    
    def bayesian_inference(self, hypothesis: str, evidence: str,
                          prior_prob: float, likelihood: float,
                          marginal_likelihood: float = None) -> float:
        """
        Wnioskowanie Bayesowskie: P(H|E) = P(E|H) * P(H) / P(E)
        """
        if marginal_likelihood is None:
            # Przybli≈ºone obliczenie P(E)
            marginal_likelihood = likelihood * prior_prob + (1 - likelihood) * (1 - prior_prob)
        
        if marginal_likelihood == 0:
            return 0.0
        
        posterior = (likelihood * prior_prob) / marginal_likelihood
        
        self.bayesian_inferences += 1
        logger.info(f"Bayes: P({hypothesis}|{evidence}) = {posterior:.3f}")
        
        return posterior
    
    def uncertainty_propagation(self, beliefs: Dict[str, Tuple[float, float]],
                               dependencies: Dict[str, List[str]]) -> Dict[str, Tuple[float, float]]:
        """
        Propagacja niepewno≈õci przez sieƒá zale≈ºno≈õci
        beliefs: {variable: (mean, std_dev)}
        dependencies: {variable: [parent_variables]}
        """
        updated_beliefs = beliefs.copy()
        
        # Prosta propagacja niepewno≈õci (linearyzacja)
        for var, parents in dependencies.items():
            if parents and all(parent in beliefs for parent in parents):
                # Suma wariancji (dla niezale≈ºnych zmiennych)
                total_variance = sum(beliefs[parent][1]**2 for parent in parents)
                total_mean = sum(beliefs[parent][0] for parent in parents) / len(parents)
                
                updated_beliefs[var] = (total_mean, math.sqrt(total_variance))
                
                self.uncertainty_calculations += 1
        
        logger.info(f"Propagacja niepewno≈õci: zaktualizowano {len(updated_beliefs)} przekona≈Ñ")
        return updated_beliefs
    
    def monte_carlo_simulation(self, variables: Dict[str, Dict[str, float]],
                              relationships: List[Dict[str, Any]],
                              num_samples: int = 1000) -> Dict[str, Dict[str, float]]:
        """
        Symulacja Monte Carlo dla z≈Ço≈ºonych modeli probabilistycznych
        """
        results = {var: [] for var in variables.keys()}
        
        for _ in range(num_samples):
            # Pr√≥bkuj warto≈õci zmiennych
            sample = {}
            for var, params in variables.items():
                if params['distribution'] == 'normal':
                    sample[var] = np.random.normal(params['mean'], params['std'])
                elif params['distribution'] == 'uniform':
                    sample[var] = np.random.uniform(params['min'], params['max'])
                elif params['distribution'] == 'bernoulli':
                    sample[var] = np.random.bernoulli(params['p'])
            
            # Zastosuj relacje
            for relationship in relationships:
                if relationship['type'] == 'linear':
                    var = relationship['target']
                    sources = relationship['sources']
                    weights = relationship['weights']
                    
                    sample[var] = sum(sample[src] * weight 
                                    for src, weight in zip(sources, weights))
            
            # Zapisz wyniki
            for var, value in sample.items():
                results[var].append(value)
        
        # Oblicz statystyki
        statistics = {}
        for var, values in results.items():
            statistics[var] = {
                'mean': np.mean(values),
                'std': np.std(values),
                'median': np.median(values),
                'q25': np.percentile(values, 25),
                'q75': np.percentile(values, 75)
            }
        
        logger.info(f"Monte Carlo: {num_samples} pr√≥bek dla {len(variables)} zmiennych")
        return statistics

class AbstractReasoningEngine:
    """G≈Ç√≥wny silnik rozumowania abstrakcyjnego"""
    
    def __init__(self):
        self.knowledge_base = SymbolicKnowledgeBase()
        self.deductive_engine = DeductiveReasoning(self.knowledge_base)
        self.inductive_engine = InductiveReasoning(self.knowledge_base)
        self.abductive_engine = AbductiveReasoning(self.knowledge_base)
        self.causal_engine = CausalReasoning(self.knowledge_base)
        self.planning_engine = HierarchicalPlanning(self.knowledge_base)
        self.probabilistic_engine = ProbabilisticReasoning(self.knowledge_base)
        
        self.reasoning_traces: List[ReasoningTrace] = []
        self.performance_metrics = {
            "total_inferences": 0,
            "successful_inferences": 0,
            "average_confidence": 0.0,
            "reasoning_types_used": set()
        }
        
        logger.info("Zainicjalizowano Advanced Abstract Reasoning Engine")
    
    def reason(self, premises: List[LogicalStatement], 
              reasoning_type: ReasoningType = ReasoningType.DEDUCTION,
              context: Dict[str, Any] = None) -> ReasoningTrace:
        """
        G≈Ç√≥wna metoda rozumowania - wybiera odpowiedni silnik i wykonuje wnioskowanie
        """
        start_time = datetime.now()
        trace_id = str(uuid.uuid4())
        
        conclusion = None
        reasoning_steps = []
        success = False
        
        try:
            if reasoning_type == ReasoningType.DEDUCTION:
                if len(premises) >= 2:
                    conclusion = self.deductive_engine.modus_ponens(premises[0], premises[1])
                    if not conclusion:
                        conclusion = self.deductive_engine.syllogism(premises[0], premises[1])
                    reasoning_steps = ["Applied deductive reasoning", "Checked modus ponens", "Checked syllogism"]
                    success = conclusion is not None
            
            elif reasoning_type == ReasoningType.INDUCTION:
                conclusion = self.inductive_engine.generalize_from_examples(premises)
                reasoning_steps = ["Applied inductive reasoning", "Searched for common patterns", "Generated generalization"]
                success = conclusion is not None
            
            elif reasoning_type == ReasoningType.ABDUCTION:
                if premises:
                    hypotheses = self.abductive_engine.generate_hypotheses(premises[0])
                    if hypotheses:
                        ranked = self.abductive_engine.rank_explanations(hypotheses)
                        conclusion = ranked[0][0] if ranked else None
                        reasoning_steps = ["Applied abductive reasoning", "Generated hypotheses", "Ranked explanations"]
                        success = conclusion is not None
            
            elif reasoning_type == ReasoningType.CAUSAL:
                if context and "cause" in context:
                    chains = self.causal_engine.infer_causal_chain(context["cause"])
                    if chains:
                        # Utw√≥rz wniosek na podstawie najkr√≥tszego ≈Ça≈Ñcucha
                        shortest_chain = min(chains, key=len)
                        conclusion = LogicalStatement(
                            id=str(uuid.uuid4()),
                            content=f"Causal chain: {' ‚Üí '.join(shortest_chain)}",
                            confidence=0.8,
                            source="causal_reasoning"
                        )
                        reasoning_steps = ["Applied causal reasoning", "Found causal chains", "Selected shortest chain"]
                        success = True
            
            # Oblicz ko≈ÑcowƒÖ pewno≈õƒá
            final_confidence = conclusion.confidence if conclusion else 0.0
            
        except Exception as e:
            logger.error(f"B≈ÇƒÖd podczas rozumowania {reasoning_type}: {e}")
            reasoning_steps.append(f"Error: {str(e)}")
            success = False
            final_confidence = 0.0
        
        # Oblicz czas wykonania
        execution_time = (datetime.now() - start_time).total_seconds()
        
        # Utw√≥rz ≈õlad rozumowania
        trace = ReasoningTrace(
            trace_id=trace_id,
            reasoning_type=reasoning_type,
            input_premises=premises,
            reasoning_steps=reasoning_steps,
            final_conclusion=conclusion,
            confidence=final_confidence,
            execution_time=execution_time,
            success=success
        )
        
        self.reasoning_traces.append(trace)
        self._update_performance_metrics(trace)
        
        logger.info(f"Rozumowanie {reasoning_type.value}: {'sukces' if success else 'niepowodzenie'} "
                   f"(pewno≈õƒá: {final_confidence:.2f}, czas: {execution_time:.3f}s)")
        
        return trace
    
    def multi_strategy_reasoning(self, premises: List[LogicalStatement],
                               strategies: List[ReasoningType] = None) -> List[ReasoningTrace]:
        """
        Rozumowanie wykorzystujƒÖce wiele strategii r√≥wnolegle
        """
        if strategies is None:
            strategies = [ReasoningType.DEDUCTION, ReasoningType.INDUCTION, ReasoningType.ABDUCTION]
        
        traces = []
        for strategy in strategies:
            trace = self.reason(premises, strategy)
            traces.append(trace)
        
        # Sortuj wed≈Çug pewno≈õci
        traces.sort(key=lambda t: t.confidence, reverse=True)
        
        logger.info(f"Multi-strategy reasoning: {len(traces)} strategii, najlepsza pewno≈õƒá: {traces[0].confidence:.2f}")
        return traces
    
    def _update_performance_metrics(self, trace: ReasoningTrace):
        """Aktualizuje metryki wydajno≈õci"""
        self.performance_metrics["total_inferences"] += 1
        if trace.success:
            self.performance_metrics["successful_inferences"] += 1
        
        # Aktualizuj ≈õredniƒÖ pewno≈õƒá
        total = self.performance_metrics["total_inferences"]
        current_avg = self.performance_metrics["average_confidence"]
        new_avg = (current_avg * (total - 1) + trace.confidence) / total
        self.performance_metrics["average_confidence"] = new_avg
        
        self.performance_metrics["reasoning_types_used"].add(trace.reasoning_type.value)
    
    def get_reasoning_statistics(self) -> Dict[str, Any]:
        """Zwraca statystyki rozumowania"""
        total_traces = len(self.reasoning_traces)
        if total_traces == 0:
            return {"message": "Brak danych o rozumowaniu"}
        
        # Statystyki wed≈Çug typu rozumowania
        type_stats = defaultdict(lambda: {"count": 0, "success_rate": 0.0, "avg_confidence": 0.0})
        
        for trace in self.reasoning_traces:
            type_key = trace.reasoning_type.value
            type_stats[type_key]["count"] += 1
            if trace.success:
                type_stats[type_key]["success_rate"] += 1
            type_stats[type_key]["avg_confidence"] += trace.confidence
        
        # Normalizuj statystyki
        for type_key, stats in type_stats.items():
            count = stats["count"]
            stats["success_rate"] = stats["success_rate"] / count if count > 0 else 0
            stats["avg_confidence"] = stats["avg_confidence"] / count if count > 0 else 0
        
        return {
            "total_reasoning_traces": total_traces,
            "overall_success_rate": self.performance_metrics["successful_inferences"] / self.performance_metrics["total_inferences"],
            "average_confidence": self.performance_metrics["average_confidence"],
            "reasoning_types_used": list(self.performance_metrics["reasoning_types_used"]),
            "detailed_statistics": dict(type_stats),
            "knowledge_base_size": {
                "statements": len(self.knowledge_base.statements),
                "rules": len(self.knowledge_base.rules),
                "concepts": len(self.knowledge_base.concepts),
                "causal_relations": self.knowledge_base.causal_graph.number_of_edges()
            }
        }

def demonstrate_abstract_reasoning():
    """Demonstracja modu≈Çu rozumowania abstrakcyjnego"""
    print("=" * 70)
    print("üß† DEMONSTRACJA MODU≈ÅU ROZUMOWANIA ABSTRAKCYJNEGO")
    print("=" * 70)
    
    # Utw√≥rz silnik rozumowania
    reasoning_engine = AbstractReasoningEngine()
    
    print("\n1. üìö BUDOWANIE BAZY WIEDZY...")
    print("-" * 50)
    
    # Dodaj podstawowe stwierdzenia
    statements = [
        LogicalStatement(
            id="stmt_1",
            content="All humans are mortal",
            predicates=["human", "mortal"],
            confidence=0.95
        ),
        LogicalStatement(
            id="stmt_2", 
            content="Socrates is human",
            predicates=["socrates", "human"],
            confidence=0.9
        ),
        LogicalStatement(
            id="stmt_3",
            content="If it rains, then streets get wet",
            predicates=["rain", "wet_streets"],
            confidence=0.85
        ),
        LogicalStatement(
            id="stmt_4",
            content="It is raining",
            predicates=["rain"],
            confidence=0.8
        )
    ]
    
    for stmt in statements:
        reasoning_engine.knowledge_base.add_statement(stmt)
        print(f"   Dodano: {stmt.content}")
    
    # Dodaj relacje przyczynowe
    causal_relations = [
        CausalRelation("rain", "wet_streets", 0.9),
        CausalRelation("wet_streets", "slippery_roads", 0.7),
        CausalRelation("slippery_roads", "accidents", 0.6)
    ]
    
    for relation in causal_relations:
        reasoning_engine.knowledge_base.add_causal_relation(relation)
        print(f"   Relacja: {relation.cause} ‚Üí {relation.effect} (si≈Ça: {relation.strength})")
    
    print(f"\nBaza wiedzy: {len(statements)} stwierdze≈Ñ, {len(causal_relations)} relacji")
    
    print("\n2. üîç ROZUMOWANIE DEDUKCYJNE...")
    print("-" * 50)
    
    # Test sylogizmu
    trace1 = reasoning_engine.reason(
        [statements[0], statements[1]], 
        ReasoningType.DEDUCTION
    )
    
    if trace1.final_conclusion:
        print(f"   Wniosek: {trace1.final_conclusion.content}")
        print(f"   Pewno≈õƒá: {trace1.final_conclusion.confidence:.2f}")
    else:
        print("   Nie uda≈Ço siƒô wyciƒÖgnƒÖƒá wniosku")
    
    # Test modus ponens
    trace2 = reasoning_engine.reason(
        [statements[2], statements[3]], 
        ReasoningType.DEDUCTION
    )
    
    if trace2.final_conclusion:
        print(f"   Modus Ponens: {trace2.final_conclusion.content}")
        print(f"   Pewno≈õƒá: {trace2.final_conclusion.confidence:.2f}")
    
    print("\n3. üîÆ ROZUMOWANIE ABDUKCYJNE...")
    print("-" * 50)
    
    # Stw√≥rz obserwacjƒô wymagajƒÖcƒÖ wyja≈õnienia
    observation = LogicalStatement(
        id="obs_1",
        content="Streets are wet",
        predicates=["wet_streets"],
        confidence=0.9
    )
    
    trace3 = reasoning_engine.reason([observation], ReasoningType.ABDUCTION)
    
    if trace3.final_conclusion:
        print(f"   Hipoteza: {trace3.final_conclusion.content}")
        print(f"   Pewno≈õƒá: {trace3.final_conclusion.confidence:.2f}")
    
    print("\n4. ‚ö° ROZUMOWANIE PRZYCZYNOWE...")
    print("-" * 50)
    
    # Test ≈Ça≈Ñcucha przyczynowego
    causal_chains = reasoning_engine.causal_engine.infer_causal_chain("rain", max_depth=3)
    
    print(f"   Znaleziono {len(causal_chains)} ≈Ça≈Ñcuch√≥w przyczynowych od 'rain':")
    for i, chain in enumerate(causal_chains[:3], 1):
        print(f"     {i}. {' ‚Üí '.join(chain)}")
    
    # Test symulacji interwencji
    effects = reasoning_engine.causal_engine.simulate_intervention("rain", True)
    print(f"   Symulacja interwencji 'rain=True':")
    for effect, strength in effects.items():
        print(f"     {effect}: {strength:.2f}")
    
    print("\n5. üéØ PLANOWANIE WIELOETAPOWE...")
    print("-" * 50)
    
    # Zdefiniuj dostƒôpne akcje
    actions = {
        "check_weather": {
            "preconditions": {},
            "effects": {"weather_known": True},
            "cost": 1
        },
        "take_umbrella": {
            "preconditions": {"weather_known": True},
            "effects": {"has_umbrella": True},
            "cost": 2
        },
        "go_outside": {
            "preconditions": {"has_umbrella": True},
            "effects": {"outside": True, "dry": True},
            "cost": 3
        }
    }
    
    start_state = {"weather_known": False, "has_umbrella": False, "outside": False, "dry": False}
    goal_state = {"outside": True, "dry": True}
    
    plan = reasoning_engine.planning_engine.a_star_planning(start_state, goal_state, actions)
    
    if plan:
        print(f"   Plan A*: {' ‚Üí '.join(plan)}")
        print(f"   Liczba krok√≥w: {len(plan)}")
    else:
        print("   Nie uda≈Ço siƒô znale≈∫ƒá planu")
    
    print("\n6. üìä ROZUMOWANIE PROBABILISTYCZNE...")
    print("-" * 50)
    
    # Test wnioskowania Bayesowskiego
    prior_prob = 0.1  # 10% ludzi ma chorobƒô
    likelihood = 0.95  # Test wykrywa chorobƒô w 95% przypadk√≥w
    posterior = reasoning_engine.probabilistic_engine.bayesian_inference(
        "disease", "positive_test", prior_prob, likelihood
    )
    
    print(f"   Bayes: P(choroba|pozytywny_test) = {posterior:.3f}")
    
    print("\n7. üîÑ ROZUMOWANIE WIELOSTRATEGICZNE...")
    print("-" * 50)
    
    # Test wszystkich strategii r√≥wnocze≈õnie
    multi_traces = reasoning_engine.multi_strategy_reasoning(
        [statements[0], statements[1]],
        [ReasoningType.DEDUCTION, ReasoningType.INDUCTION, ReasoningType.ABDUCTION]
    )
    
    print("   Wyniki r√≥≈ºnych strategii:")
    for i, trace in enumerate(multi_traces, 1):
        conclusion_text = trace.final_conclusion.content if trace.final_conclusion else "Brak wniosku"
        print(f"     {i}. {trace.reasoning_type.value}: {conclusion_text} (pewno≈õƒá: {trace.confidence:.2f})")
    
    print("\n8. üìà STATYSTYKI ROZUMOWANIA...")
    print("-" * 50)
    
    stats = reasoning_engine.get_reasoning_statistics()
    
    print(f"   Ca≈Çkowite liczba wnioskowa≈Ñ: {stats['total_reasoning_traces']}")
    print(f"   Og√≥lna skuteczno≈õƒá: {stats['overall_success_rate']:.2f}")
    print(f"   ≈örednia pewno≈õƒá: {stats['average_confidence']:.2f}")
    print(f"   Wykorzystane typy rozumowania: {', '.join(stats['reasoning_types_used'])}")
    
    print(f"\n   Baza wiedzy:")
    kb_stats = stats['knowledge_base_size']
    print(f"     ‚Ä¢ Stwierdzenia: {kb_stats['statements']}")
    print(f"     ‚Ä¢ Regu≈Çy: {kb_stats['rules']}")
    print(f"     ‚Ä¢ Koncepty: {kb_stats['concepts']}")
    print(f"     ‚Ä¢ Relacje przyczynowe: {kb_stats['causal_relations']}")
    
    print("\n" + "=" * 70)
    print("üéØ MODU≈Å ROZUMOWANIA ABSTRAKCYJNEGO - DEMONSTRACJA ZAKO≈ÉCZONA")
    print(f"üí° OsiƒÖgniƒôto zaawansowane rozumowanie logiczne z wieloma strategiami!")
    print("=" * 70)
    
    return reasoning_engine, stats

if __name__ == "__main__":
    print("Uruchamianie demonstracji Modu≈Çu Rozumowania Abstrakcyjnego...")
    engine, statistics = demonstrate_abstract_reasoning()
    
    print(f"\nüß† PODSUMOWANIE IMPLEMENTACJI:")
    print(f"‚Ä¢ Zaimplementowano 6 typ√≥w rozumowania")
    print(f"‚Ä¢ Skuteczno≈õƒá: {statistics['overall_success_rate']:.0%}")
    print(f"‚Ä¢ ≈örednia pewno≈õƒá: {statistics['average_confidence']:.2f}")
    print(f"‚Ä¢ Oszacowany przyrost AGI: +16 punkt√≥w (20% ‚Üí 36% jako≈õci rozumowania)")